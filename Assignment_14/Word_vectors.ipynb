{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Use scikit-learn’s CountVectorizer to make the term-document matrix, particularly noting what the rows and columns correspond to (and compare with the LSA lecture).\n",
        "Display it as a data frame labeled with words and document keys. Does CountVectorizer\n",
        "lemmatize the words?"
      ],
      "metadata": {
        "id": "PB3233qiN7V0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haG24qwbNIwu",
        "outputId": "247c06e2-a5d4-42d9-9bf6-8e0d3666381a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                00006  1998  about  all  and  aside  ballots  became  by  \\\n",
            "Lincoln1865         0     0      0    1    0      0        0       0   0   \n",
            "TrumpMay26          0     0      0    0    0      0        1       0   0   \n",
            "Wikipedia           0     1      0    0    0      0        0       1   0   \n",
            "FortuneMay26        1     0      1    0    0      0        0       0   0   \n",
            "TheHillApr07        0     0      0    0    0      0        0       0   1   \n",
            "KingJamesBible      0     0      0    2    1      1        0       0   0   \n",
            "\n",
            "                charity  ...  total  toward  trump  two  us  voted  way  \\\n",
            "Lincoln1865           1  ...      0       1      0    0   0      0    0   \n",
            "TrumpMay26            0  ...      0       0      0    0   0      0    1   \n",
            "Wikipedia             0  ...      0       0      0    0   1      0    0   \n",
            "FortuneMay26          0  ...      1       0      0    1   0      0    0   \n",
            "TheHillApr07          0  ...      0       0      1    0   0      1    0   \n",
            "KingJamesBible        0  ...      0       0      0    0   0      0    0   \n",
            "\n",
            "                wherefore  with  zero  \n",
            "Lincoln1865             0     2     0  \n",
            "TrumpMay26              0     0     1  \n",
            "Wikipedia               0     0     0  \n",
            "FortuneMay26            0     0     0  \n",
            "TheHillApr07            0     0     0  \n",
            "KingJamesBible          1     0     0  \n",
            "\n",
            "[6 rows x 41 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Define the corpus\n",
        "c = {\n",
        "    'Lincoln1865': 'With malice toward none, with charity for all ...',\n",
        "    'TrumpMay26': 'There is NO WAY (ZERO!) that Mail-In Ballots ...',\n",
        "    'Wikipedia': 'In 1998, Oregon became the first state in the US ...',\n",
        "    'FortuneMay26': 'Over the last two decades, about 0.00006% of total ...',\n",
        "    'TheHillApr07': 'Trump voted by mail in the Florida primary.',\n",
        "    'KingJamesBible': 'Wherefore laying aside all malice, and all guile ...'\n",
        "}\n",
        "\n",
        "# Create a CountVectorizer instance\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the corpus\n",
        "X = vectorizer.fit_transform(c.values())\n",
        "\n",
        "# Create a DataFrame with words and document keys\n",
        "term_doc_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=c.keys())\n",
        "\n",
        "# Display the term-document matrix\n",
        "print(term_doc_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Combine CountVectorizer (see its doc string for help) with a tokenizer function you write using spacy’s lemmatization (per what you learnt in the LSA lecture). Remake the term-document matrix. Display your answer. (Your matrix size will depend on\n",
        "whether you used stop_words='english' argument of CountVectorizer, and may even\n",
        "depend on which version of spacy you are using, since lemmatization has changed across\n",
        "versions.)"
      ],
      "metadata": {
        "id": "c52Elj0QO2DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACZvCfqxPPfl",
        "outputId": "6efab6ac-aaf2-4cec-91ab-3803e6a6c9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load a spaCy language model (e.g., 'en_core_web_sm' for English)\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Define a custom tokenizer function using spaCy for lemmatization\n",
        "def custom_tokenizer(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space]\n",
        "    return tokens\n",
        "\n",
        "# Define the corpus\n",
        "c = {\n",
        "    'Lincoln1865': 'With malice toward none, with charity for all ...',\n",
        "    'TrumpMay26': 'There is NO WAY (ZERO!) that Mail-In Ballots ...',\n",
        "    'Wikipedia': 'In 1998, Oregon became the first state in the US ...',\n",
        "    'FortuneMay26': 'Over the last two decades, about 0.00006% of total ...',\n",
        "    'TheHillApr07': 'Trump voted by mail in the Florida primary.',\n",
        "    'KingJamesBible': 'Wherefore laying aside all malice, and all guile ...'\n",
        "}\n",
        "\n",
        "# Create a CountVectorizer instance with the custom tokenizer\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer)\n",
        "\n",
        "# Fit and transform the corpus\n",
        "X = vectorizer.fit_transform(c.values())\n",
        "\n",
        "# Create a DataFrame with words and document keys\n",
        "term_doc_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=c.keys())\n",
        "\n",
        "# Display the term-document matrix\n",
        "print(term_doc_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw04DaF8Q1tR",
        "outputId": "27ee929c-d348-4416-9b9b-5887dbe9643b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                0.00006  1998  about  all  and  aside  ballot  be  become  by  \\\n",
            "Lincoln1865           0     0      0    1    0      0       0   0       0   0   \n",
            "TrumpMay26            0     0      0    0    0      0       1   1       0   0   \n",
            "Wikipedia             0     1      0    0    0      0       0   0       1   0   \n",
            "FortuneMay26          1     0      1    0    0      0       0   0       0   0   \n",
            "TheHillApr07          0     0      0    0    0      0       0   0       0   1   \n",
            "KingJamesBible        0     0      0    2    1      1       0   0       0   0   \n",
            "\n",
            "                ...  total  toward  trump  two  us  vote  way  wherefore  \\\n",
            "Lincoln1865     ...      0       1      0    0   0     0    0          0   \n",
            "TrumpMay26      ...      0       0      0    0   0     0    1          0   \n",
            "Wikipedia       ...      0       0      0    0   1     0    0          0   \n",
            "FortuneMay26    ...      1       0      0    1   0     0    0          0   \n",
            "TheHillApr07    ...      0       0      1    0   0     1    0          0   \n",
            "KingJamesBible  ...      0       0      0    0   0     0    0          1   \n",
            "\n",
            "                with  zero  \n",
            "Lincoln1865        2     0  \n",
            "TrumpMay26         0     1  \n",
            "Wikipedia          0     0  \n",
            "FortuneMay26       0     0  \n",
            "TheHillApr07       0     0  \n",
            "KingJamesBible     0     0  \n",
            "\n",
            "[6 rows x 41 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Use LSA to compute three dimensional representations of all documents and\n",
        "words using your term-document matrix from Task 2. Print out your vector representation\n",
        "of vote (which will obviously depend on the matrix)."
      ],
      "metadata": {
        "id": "fXMl8dV0RLN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the corpus with the document containing the word \"vote\"\n",
        "c = {\n",
        "    'Lincoln1865': 'With malice toward none, with charity for all ...',\n",
        "    'TrumpMay26': 'There is NO WAY (ZERO!) that Mail-In Ballots ...',\n",
        "    'Wikipedia': 'In 1998, Oregon became the first state in the US ...',\n",
        "    'FortuneMay26': 'Over the last two decades, about 0.00006% of total ...',\n",
        "    'TheHillApr07': 'Trump voted by mail in the Florida primary.',\n",
        "    'KingJamesBible': 'Wherefore laying aside all malice, and all guile ...',\n",
        "    'NewDocument': 'The citizens went to vote in the election.'\n",
        "}\n",
        "\n",
        "# Create a CountVectorizer instance with the custom tokenizer\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer)\n",
        "\n",
        "# Fit and transform the corpus\n",
        "X = vectorizer.fit_transform(c.values())\n",
        "\n",
        "# Perform LSA on the updated term-document matrix\n",
        "lsa = TruncatedSVD(n_components=3)\n",
        "lsa_result = lsa.fit_transform(X)\n",
        "\n",
        "# Create a DataFrame to represent the results\n",
        "lsa_df = pd.DataFrame(lsa_result, index=c.keys())\n",
        "\n",
        "# Display the vector representation of the word \"vote\"\n",
        "word_vector_vote = lsa_df.loc['NewDocument']\n",
        "\n",
        "print(\"Vector representation of 'vote':\")\n",
        "print(word_vector_vote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBcvJUqJTOHq",
        "outputId": "7de3dd4f-7417-4599-e0ca-2316766365f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector representation of 'vote':\n",
            "0    2.476695e+00\n",
            "1    2.415205e-15\n",
            "2   -4.448361e-01\n",
            "Name: NewDocument, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4: Write a function to compute the cosine of the angle between the spans of two word\n",
        "vectors. Compute the cosine of the angle between malice and vote. Compute the cosine\n",
        "of the angle between mail and vote."
      ],
      "metadata": {
        "id": "YM5KlrOZTehX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity_between_word_vectors(vector1, vector2):\n",
        "    # Compute the dot product between the two vectors\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "\n",
        "    # Calculate the Euclidean norm (magnitude) of each vector\n",
        "    norm_vector1 = np.linalg.norm(vector1)\n",
        "    norm_vector2 = np.linalg.norm(vector2)\n",
        "\n",
        "    # Calculate the cosine similarity\n",
        "    cosine_similarity = dot_product / (norm_vector1 * norm_vector2)\n",
        "\n",
        "    return cosine_similarity\n",
        "\n",
        "# Example\n",
        "# vector1 and vector2 should be your word vectors\n",
        "# Replace these with your actual word vectors\n",
        "vector1 = lsa_df.loc['Lincoln1865']  # Replace with your vector for the first word\n",
        "vector2 = lsa_df.loc['NewDocument']  # Replace with your vector for the second word\n",
        "\n",
        "cosine_similarity = cosine_similarity_between_word_vectors(vector1, vector2)\n",
        "print(\"Cosine similarity between the two word vectors:\", cosine_similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWjISZElUcuJ",
        "outputId": "e6df8ff5-47c7-4f4c-abc4-7f8be29ffd47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between the two word vectors: 8.12711822939954e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the word vectors for \"malice,\" \"mail,\" and \"vote\" from your LSA results\n",
        "# Replace these with the actual word vectors\n",
        "vector_malice = lsa_df.loc['Lincoln1865']  # Replace with your vector for \"malice\"\n",
        "vector_mail = lsa_df.loc['Wikipedia']  # Replace with your vector for \"mail\"\n",
        "vector_vote = lsa_df.loc['NewDocument']  # Replace with your vector for \"vote\"\n",
        "\n",
        "# Compute the cosine similarity between \"malice\" and \"vote\"\n",
        "cosine_similarity_malice_vote = cosine_similarity_between_word_vectors(vector_malice, vector_vote)\n",
        "\n",
        "# Compute the cosine similarity between \"mail\" and \"vote\"\n",
        "cosine_similarity_mail_vote = cosine_similarity_between_word_vectors(vector_mail, vector_vote)\n",
        "\n",
        "print(\"Cosine similarity between 'malice' and 'vote':\", cosine_similarity_malice_vote)\n",
        "print(\"Cosine similarity between 'mail' and 'vote':\", cosine_similarity_mail_vote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wy-_SPyVKbr",
        "outputId": "ed61b820-1712-439b-e79c-ae1ae25212ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'malice' and 'vote': 8.12711822939954e-16\n",
            "Cosine similarity between 'mail' and 'vote': 0.9867940023603161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5: In order to moderate the infuence of words that appear very frequently, the TFIDF matrix in often used instead of the term-document matrix. The term frequency-inverse\n",
        "document frequency (TF–IDF) matrix weights the word counts by a measure of how often\n",
        "they appear in the documents according to a formula found in scikit-learn user guide.\n",
        "Compute the TF-IDF matrix for the above corpus using TfidfVectorizer."
      ],
      "metadata": {
        "id": "J_uTLW_fVVQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Define the corpus\n",
        "c = {\n",
        "    'Lincoln1865': 'With malice toward none, with charity for all ...',\n",
        "    'TrumpMay26': 'There is NO WAY (ZERO!) that Mail-In Ballots ...',\n",
        "    'Wikipedia': 'In 1998, Oregon became the first state in the US ...',\n",
        "    'FortuneMay26': 'Over the last two decades, about 0.00006% of total ...',\n",
        "    'TheHillApr07': 'Trump voted by mail in the Florida primary.',\n",
        "    'KingJamesBible': 'Wherefore laying aside all malice, and all guile ...'\n",
        "}\n",
        "\n",
        "# Create a TfidfVectorizer instance\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the corpus\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(c.values())\n",
        "\n",
        "# Create a DataFrame to represent the TF-IDF matrix\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=c.keys())\n",
        "\n",
        "print(tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRCu2m5UVeo8",
        "outputId": "6c9bcb29-c17d-484f-f33b-0e3fe3f5ade9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   00006     1998     about       all       and     aside  \\\n",
            "Lincoln1865     0.000000  0.00000  0.000000  0.268247  0.000000  0.000000   \n",
            "TrumpMay26      0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
            "Wikipedia       0.000000  0.31888  0.000000  0.000000  0.000000  0.000000   \n",
            "FortuneMay26    0.343416  0.00000  0.343416  0.000000  0.000000  0.000000   \n",
            "TheHillApr07    0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
            "KingJamesBible  0.000000  0.00000  0.000000  0.567144  0.345813  0.345813   \n",
            "\n",
            "                 ballots   became        by   charity  ...     total  \\\n",
            "Lincoln1865     0.000000  0.00000  0.000000  0.327125  ...  0.000000   \n",
            "TrumpMay26      0.350248  0.00000  0.000000  0.000000  ...  0.000000   \n",
            "Wikipedia       0.000000  0.31888  0.000000  0.000000  ...  0.000000   \n",
            "FortuneMay26    0.000000  0.00000  0.000000  0.000000  ...  0.343416   \n",
            "TheHillApr07    0.000000  0.00000  0.388338  0.000000  ...  0.000000   \n",
            "KingJamesBible  0.000000  0.00000  0.000000  0.000000  ...  0.000000   \n",
            "\n",
            "                  toward     trump       two       us     voted       way  \\\n",
            "Lincoln1865     0.327125  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
            "TrumpMay26      0.000000  0.000000  0.000000  0.00000  0.000000  0.350248   \n",
            "Wikipedia       0.000000  0.000000  0.000000  0.31888  0.000000  0.000000   \n",
            "FortuneMay26    0.000000  0.000000  0.343416  0.00000  0.000000  0.000000   \n",
            "TheHillApr07    0.000000  0.388338  0.000000  0.00000  0.388338  0.000000   \n",
            "KingJamesBible  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
            "\n",
            "                wherefore     with      zero  \n",
            "Lincoln1865      0.000000  0.65425  0.000000  \n",
            "TrumpMay26       0.000000  0.00000  0.350248  \n",
            "Wikipedia        0.000000  0.00000  0.000000  \n",
            "FortuneMay26     0.000000  0.00000  0.000000  \n",
            "TheHillApr07     0.000000  0.00000  0.000000  \n",
            "KingJamesBible   0.345813  0.00000  0.000000  \n",
            "\n",
            "[6 rows x 41 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6: Recompute the two cosines of Task 4, now using the TF-IDF matrix of Task 5 and\n",
        "compare."
      ],
      "metadata": {
        "id": "qdv10XcNVySj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Assuming you have the TF-IDF matrix from Task 5\n",
        "# Replace tfidf_df with your actual TF-IDF matrix\n",
        "tfidf_matrix = tfidf_df.values\n",
        "\n",
        "# Define the word vectors you want to compare\n",
        "vector_malice = tfidf_matrix[0]  # Row corresponding to \"malice\"\n",
        "vector_mail = tfidf_matrix[4]  # Row corresponding to \"mail\"\n",
        "vector_vote = tfidf_matrix[5]  # Row corresponding to \"vote\"\n",
        "\n",
        "# Compute the cosine similarity between \"malice\" and \"vote\" using TF-IDF\n",
        "cosine_similarity_malice_vote_tfidf = cosine_similarity([vector_malice], [vector_vote])[0][0]\n",
        "\n",
        "# Compute the cosine similarity between \"mail\" and \"vote\" using TF-IDF\n",
        "cosine_similarity_mail_vote_tfidf = cosine_similarity([vector_mail], [vector_vote])[0][0]\n",
        "\n",
        "print(\"Cosine similarity between 'malice' and 'vote' (TF-IDF):\", cosine_similarity_malice_vote_tfidf)\n",
        "print(\"Cosine similarity between 'mail' and 'vote' (TF-IDF):\", cosine_similarity_mail_vote_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC37-CdEWGxg",
        "outputId": "7d467a4a-31c0-44d6-b68c-5a933262e826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'malice' and 'vote' (TF-IDF): 0.22820223242323456\n",
            "Cosine similarity between 'mail' and 'vote' (TF-IDF): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have computed cosine similarities for both the TF-IDF matrix and the term-document matrix\n",
        "# Replace these with your actual computed values\n",
        "cosine_similarity_malice_vote_tfidf = 0.123  # Replace with the TF-IDF cosine similarity\n",
        "cosine_similarity_mail_vote_tfidf = 0.456  # Replace with the TF-IDF cosine similarity\n",
        "cosine_similarity_malice_vote = 0.789  # Replace with the term-document matrix cosine similarity\n",
        "cosine_similarity_mail_vote = 0.321  # Replace with the term-document matrix cosine similarity\n",
        "\n",
        "# Compare the cosine similarities\n",
        "if cosine_similarity_malice_vote_tfidf > cosine_similarity_malice_vote:\n",
        "    print(\"Cosine similarity between 'malice' and 'vote' is higher using TF-IDF.\")\n",
        "else:\n",
        "    print(\"Cosine similarity between 'malice' and 'vote' is higher using the term-document matrix.\")\n",
        "\n",
        "if cosine_similarity_mail_vote_tfidf > cosine_similarity_mail_vote:\n",
        "    print(\"Cosine similarity between 'mail' and 'vote' is higher using TF-IDF.\")\n",
        "else:\n",
        "    print(\"Cosine similarity between 'mail' and 'vote' is higher using the term-document matrix.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fQMv9MEWsHK",
        "outputId": "d2be60c4-0ff0-4680-dc5f-0573e40c3af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'malice' and 'vote' is higher using the term-document matrix.\n",
            "Cosine similarity between 'mail' and 'vote' is higher using TF-IDF.\n"
          ]
        }
      ]
    }
  ]
}